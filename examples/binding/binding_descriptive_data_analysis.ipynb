{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load fasta file\n",
    "\n",
    "def load_fasta(file):\n",
    "    fasta_dict = {}\n",
    "    header = None\n",
    "    sequence_lines = []\n",
    "\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\">\"):\n",
    "                if header:\n",
    "                    fasta_dict[header] = ''.join(sequence_lines)\n",
    "                header = line[1:].strip()\n",
    "                sequence_lines = []\n",
    "            else:\n",
    "                sequence_lines.append(line)\n",
    "\n",
    "        # Add the last record\n",
    "        if header:\n",
    "            fasta_dict[header] = ''.join(sequence_lines)\n",
    "\n",
    "    return fasta_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sequences\n",
    "sequences = load_fasta(\"data/all.fasta\")\n",
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand length of sequences\n",
    "sequences_lengths = [len(seq) for seq in sequences.values()]\n",
    "\n",
    "min(sequences_lengths), max(sequences_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sequence lengths\n",
    "\n",
    "df = pd.DataFrame(sequences_lengths, columns=[\"length\"])\n",
    "df[\"length\"] = df[\"length\"].astype(int)\n",
    "# add title \n",
    "df[\"title\"] = \"Length of sequences in all.fasta\"\n",
    "fig = px.histogram(df, x=\"length\", nbins=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data splits \n",
    "\n",
    "data_splits = pd.DataFrame(columns=[\"id\", \"split\"])\n",
    "\n",
    "for split in range(1, 6):\n",
    "    ids = pd.read_csv(f\"data/ids_split{split}.txt\", header=None)\n",
    "    ids = ids[0].tolist()\n",
    "    data = {\"id\": ids, \"split\": split}\n",
    "    data = pd.DataFrame(data)\n",
    "    data_splits = pd.concat([data_splits, data])\n",
    "\n",
    "data_splits['split'].value_counts(), data_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in test labels\n",
    "test_ids = pd.read_csv(\"data/uniprot_test.txt\", header=None)\n",
    "test_ids = test_ids[0].tolist()\n",
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = data_splits['id'].tolist() + test_ids\n",
    "len(all_ids), len(set(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset of the sequences with only training sequences\n",
    "\n",
    "training_ids = data_splits['id'].tolist()\n",
    "train_sequences = {k: v for k, v in sequences.items() if k in training_ids}\n",
    "len(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = [len(v) for k, v in train_sequences.items()]\n",
    "residue_number_all = sum(seq_lengths)\n",
    "len(training_ids), residue_number_all # number of required embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binding site files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load binding sites files\n",
    "\n",
    "binding_sites_files = [f for f in os.listdir(\"data\") if f.startswith(\"binding_residues\")]\n",
    "binding_sites = {}\n",
    "\n",
    "for file in binding_sites_files:\n",
    "    ligand = file.split(\"_\")[-1].replace(\".txt\", \"\")\n",
    "    with open(f\"data/{file}\") as f:\n",
    "        binding_sites[ligand] = {}\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            id, sites = line.split(\"\\t\")\n",
    "            id = id.strip()\n",
    "            sites = sites.split(\" \")\n",
    "            binding_sites[ligand][id] = sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_sites_df = pd.DataFrame(columns=[\"protein_id\", \"ligand\", \"site\"])\n",
    "\n",
    "for ligand, ids in binding_sites.items():\n",
    "    for id, sites in ids.items():\n",
    "        for site in sites:\n",
    "            data = {\"protein_id\": id, \"ligand\": ligand, \"site\": site}\n",
    "            binding_sites_df = pd.concat([binding_sites_df, pd.DataFrame(data, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_sites_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of protein_ids in binding sites data \n",
    "print(\"Number of protein_ids in binding sites data: \", len(binding_sites_df[\"protein_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_sites_df = binding_sites_df.assign(site=binding_sites_df['site'].str.split(',')).explode('site').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show any rows for which protein_id and site are duplicated\n",
    "grouped = binding_sites_df.groupby(['protein_id', 'site'])['ligand'].nunique().reset_index(name='n_unique_ligands')\n",
    "filtered = grouped[grouped['n_unique_ligands'].isin([2, 3])]\n",
    "print(f\"Number of protein id's with multiple ligands and sites: {filtered['protein_id'].nunique()}\")\n",
    "\n",
    "# plot histogram of number of ligands per protein\n",
    "fig = px.histogram(grouped, x=\"n_unique_ligands\", nbins=10)\n",
    "fig.update_layout(title=\"Number of ligands per protein\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset binding data to proteins from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check howmany of the train_ids are in the binding sites data\n",
    "\n",
    "train_ids_in_binding_sites = binding_sites_df[binding_sites_df[\"protein_id\"].isin(train_sequences.keys())]['protein_id'].unique()\n",
    "len(train_ids_in_binding_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter down binding sites to training ids\n",
    "\n",
    "binding_sites_train_df = binding_sites_df[binding_sites_df[\"protein_id\"].isin(train_sequences.keys())]\n",
    "print(\"Shape of binding sites train df: \", binding_sites_train_df.shape)\n",
    "print(\"Number of binding sites in training data: \", len(binding_sites_train_df))\n",
    "print(\"Number of unique protein ids in training data: \", binding_sites_train_df[\"protein_id\"].nunique())\n",
    "print(\"Number of unique ligands in training data: \", binding_sites_train_df[\"ligand\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_combinations = binding_sites_train_df[['protein_id', 'site']].drop_duplicates().shape[0]\n",
    "print(\"Number of unique combinations of protein_id and site: \", n_unique_combinations)\n",
    "print(\"Number of unique combinations of protein_id and site not in binding sites data: \", residue_number_all - n_unique_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each ligand class - show number of unique protein_ids, number of sites\n",
    "\n",
    "for ligand in binding_sites_train_df['ligand'].unique():\n",
    "    ligand_df = binding_sites_train_df[binding_sites_train_df['ligand'] == ligand]\n",
    "    n_unique_proteins = ligand_df['protein_id'].nunique()\n",
    "    n_sites = ligand_df.shape[0]\n",
    "    print(f\"Ligand: {ligand}, Unique Proteins: {n_unique_proteins}, Unique Sites: {n_sites}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  again check for duplicates of binding labels for multiple binding types\n",
    "\n",
    "# show any rows for which protein_id and site are duplicated\n",
    "grouped = binding_sites_train_df.groupby(['protein_id', 'site'])['ligand'].nunique().reset_index(name='n_unique_ligands')\n",
    "filtered = grouped[grouped['n_unique_ligands'].isin([2, 3])]\n",
    "print(f\"Number of protein id's with multiple ligands and sites: {filtered['protein_id'].nunique()}\")\n",
    "\n",
    "# plot histogram of number of ligands per protein\n",
    "fig = px.histogram(grouped, x=\"n_unique_ligands\", nbins=10)\n",
    "fig.update_layout(title=\"Number of ligands per protein\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ligand information for duplicated ligand labels \n",
    "\n",
    "ligands_per_site = binding_sites_train_df[binding_sites_train_df[\"protein_id\"].isin(filtered['protein_id'].unique())].groupby(['protein_id', 'site'])['ligand'].unique().reset_index(name='ligands')\n",
    "ligands_per_site['ligands_tuple'] = ligands_per_site['ligands'].apply(lambda x: tuple(sorted(x)))\n",
    "ligand_comb_counts = ligands_per_site['ligands_tuple'].value_counts()\n",
    "ligand_comb_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a joint feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for protein_id, sequence in train_sequences.items():\n",
    "    for pos in range(len(sequence)):\n",
    "        records.append({\n",
    "            'protein_id': protein_id,\n",
    "            'pos': pos +1,  # 0-based, can change to 1-based if needed\n",
    "            'residue_id': f\"{protein_id}_{pos +1}\"\n",
    "        })\n",
    "\n",
    "feature_df = pd.DataFrame(records)\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure binding_sites_train_df['site'] is int\n",
    "binding_sites_train_df['site'] = binding_sites_train_df['site'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_set = set(zip(binding_sites_train_df['protein_id'], binding_sites_train_df['site']))\n",
    "feature_df['binding'] = feature_df.apply(lambda row: 'yes' if (row['protein_id'], row['pos']) in binding_set else 'no', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['binding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ligands = binding_sites_train_df['ligand'].unique()\n",
    "# Add one column per unique ligand\n",
    "triplet_set = set(binding_sites_train_df[['protein_id', 'site', 'ligand']].itertuples(index=False, name=None))\n",
    "\n",
    "# Map of ligand â†’ set of proteins that have ANY site annotated for it\n",
    "ligand_proteins = binding_sites_train_df.groupby('ligand')['protein_id'].unique().to_dict()\n",
    "\n",
    "for ligand in unique_ligands:\n",
    "    annotated_proteins = set(ligand_proteins[ligand])\n",
    "    \n",
    "    def determine_label(row):\n",
    "        key = (row['protein_id'], row['pos'], ligand)\n",
    "        if key in triplet_set:\n",
    "            return 'yes'\n",
    "        elif row['protein_id'] in annotated_proteins:\n",
    "            return 'no'\n",
    "        else:\n",
    "            return 'no_information'\n",
    "    \n",
    "    feature_df[ligand] = feature_df.apply(determine_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['nuclear'].value_counts(), feature_df['small'].value_counts(), feature_df['metal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_cols = [col for col in feature_df.columns if col not in ['protein_id', 'pos', 'residue_id', 'binding']]\n",
    "\n",
    "def concat_ligands(row):\n",
    "    present_ligands = [lig for lig in ligand_cols if row[lig] == 'yes']\n",
    "    return \",\".join(sorted(present_ligands)) if present_ligands else \"none\"\n",
    "\n",
    "feature_df['ligand'] = feature_df.apply(concat_ligands, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df[(feature_df['small']==\"no_information\") & (feature_df['metal']==\"no_information\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['ligand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = {pid: len(seq) for pid, seq in train_sequences.items()}\n",
    "\n",
    "# Add sequence_length column\n",
    "feature_df['sequence_length'] = feature_df['protein_id'].map(sequence_lengths)\n",
    "\n",
    "# Bin the sequence lengths\n",
    "bin_size = 50  # You can change this to whatever granularity you prefer\n",
    "\n",
    "def length_to_bin(length):\n",
    "    start = (length // bin_size) * bin_size + 1\n",
    "    end = start + bin_size - 1\n",
    "    return f\"{start}-{end}\"\n",
    "\n",
    "feature_df['sequence_length_bin'] = feature_df['sequence_length'].apply(length_to_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['sequence_length_bin'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv\n",
    "\n",
    "feature_df.to_csv(\"binding_train_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export sequence fasta file containing only proteins from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export training sequences to fasta file without line breaks\n",
    "\n",
    "with open(\"binding_train_sequences.fasta\", \"w\") as f:\n",
    "    for protein_id, sequence in train_sequences.items():\n",
    "        f.write(f\">{protein_id}\\n\")\n",
    "        f.write(f\"{sequence}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
